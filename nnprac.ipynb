{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b9b3c9b-96e6-4539-a7bc-d91daf86005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54c04f63-61ef-4d5f-9a7f-5bf075249334",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('oneadvwchange.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdfd2bed-c051-4494-b8eb-67086d6de571",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.from_numpy(df['Target'].to_numpy()).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e117b866-8c61-4426-8371-29e272aeea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.from_numpy(df['Change 1'].to_numpy()).to(torch.float32)\n",
    "x2 = torch.from_numpy(df['Change 2'].to_numpy()).to(torch.float32)\n",
    "x3 = torch.from_numpy(df['Change 3'].to_numpy()).to(torch.float32)\n",
    "x4 = torch.from_numpy(df['Change 4'].to_numpy()).to(torch.float32)\n",
    "x5 = torch.from_numpy(df['Change 5'].to_numpy()).to(torch.float32)\n",
    "x6 = torch.from_numpy(df['Change 6'].to_numpy()).to(torch.float32)\n",
    "x7 = torch.from_numpy(df['Change 7'].to_numpy()).to(torch.float32)\n",
    "x8 = torch.from_numpy(df['Change 8'].to_numpy()).to(torch.float32)\n",
    "x9 = torch.from_numpy(df['Change 9'].to_numpy()).to(torch.float32)\n",
    "x10 = torch.from_numpy(df['Change 10'].to_numpy()).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dc1f669-ac00-490d-bac9-248fc5b159b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.stack([x1, x2, x3, x4, x5, x6, x7, x8, x9, x10], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9eb5f9b-823d-40d6-a6de-c026c0b472d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[:int(.8 * len(X))], y[:int(.8 * len(X))]\n",
    "X_test, y_test = X[int(.8 * len(X)):], y[int(.8 * len(X)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29b12d42-9bb5-4dc1-a6fb-5d9a5f4c711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear_layer = nn.Linear(in_features=10, out_features=1)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a330e4c-fcbc-40f3-99b9-64f301411caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(59)\n",
    "model0 = LinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9719779c-e551-40b5-bfd9-66ee88100293",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(model0.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6018332b-9519-4462-a8fa-c724402d9c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d671b424-f560-4fe4-97f3-74a23d315065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 0.474524587392807 | Test loss: 0.490283727645874\n",
      "Epoch: 100 | Train loss: 0.4744904637336731 | Test loss: 0.49029529094696045\n",
      "Epoch: 200 | Train loss: 0.4744695723056793 | Test loss: 0.4903066158294678\n",
      "Epoch: 300 | Train loss: 0.47445666790008545 | Test loss: 0.49031510949134827\n",
      "Epoch: 400 | Train loss: 0.47444799542427063 | Test loss: 0.4903232157230377\n",
      "Epoch: 500 | Train loss: 0.47444257140159607 | Test loss: 0.49033108353614807\n",
      "Epoch: 600 | Train loss: 0.4744393527507782 | Test loss: 0.4903372526168823\n",
      "Epoch: 700 | Train loss: 0.4744375944137573 | Test loss: 0.4903418719768524\n",
      "Epoch: 800 | Train loss: 0.4744364023208618 | Test loss: 0.49034520983695984\n",
      "Epoch: 900 | Train loss: 0.4744354486465454 | Test loss: 0.49034810066223145\n",
      "Epoch: 1000 | Train loss: 0.47443491220474243 | Test loss: 0.49035027623176575\n",
      "Epoch: 1100 | Train loss: 0.4744345247745514 | Test loss: 0.49035221338272095\n",
      "Epoch: 1200 | Train loss: 0.4744342565536499 | Test loss: 0.49035370349884033\n",
      "Epoch: 1300 | Train loss: 0.47443410754203796 | Test loss: 0.49035483598709106\n",
      "Epoch: 1400 | Train loss: 0.4744339883327484 | Test loss: 0.49035540223121643\n",
      "Epoch: 1500 | Train loss: 0.47443389892578125 | Test loss: 0.4903557002544403\n",
      "Epoch: 1600 | Train loss: 0.47443389892578125 | Test loss: 0.49035581946372986\n",
      "Epoch: 1700 | Train loss: 0.47443389892578125 | Test loss: 0.4903560280799866\n",
      "Epoch: 1800 | Train loss: 0.47443389892578125 | Test loss: 0.4903561770915985\n",
      "Epoch: 1900 | Train loss: 0.4744338393211365 | Test loss: 0.4903564453125\n",
      "Epoch: 2000 | Train loss: 0.4744338393211365 | Test loss: 0.4903567433357239\n",
      "Epoch: 2100 | Train loss: 0.4744338393211365 | Test loss: 0.49035704135894775\n",
      "Epoch: 2200 | Train loss: 0.4744338393211365 | Test loss: 0.490357369184494\n",
      "Epoch: 2300 | Train loss: 0.4744337797164917 | Test loss: 0.4903576672077179\n",
      "Epoch: 2400 | Train loss: 0.4744337797164917 | Test loss: 0.49035802483558655\n",
      "Epoch: 2500 | Train loss: 0.4744338393211365 | Test loss: 0.49035829305648804\n",
      "Epoch: 2600 | Train loss: 0.4744337797164917 | Test loss: 0.4903583824634552\n",
      "Epoch: 2700 | Train loss: 0.4744337797164917 | Test loss: 0.49035823345184326\n",
      "Epoch: 2800 | Train loss: 0.4744337797164917 | Test loss: 0.4903581142425537\n",
      "Epoch: 2900 | Train loss: 0.4744337797164917 | Test loss: 0.4903579652309418\n",
      "Epoch: 3000 | Train loss: 0.4744337797164917 | Test loss: 0.49035781621932983\n",
      "Epoch: 3100 | Train loss: 0.4744337797164917 | Test loss: 0.49035772681236267\n",
      "Epoch: 3200 | Train loss: 0.4744337797164917 | Test loss: 0.49035757780075073\n",
      "Epoch: 3300 | Train loss: 0.4744337797164917 | Test loss: 0.4903573989868164\n",
      "Epoch: 3400 | Train loss: 0.4744337499141693 | Test loss: 0.49035730957984924\n",
      "Epoch: 3500 | Train loss: 0.4744337797164917 | Test loss: 0.49035724997520447\n",
      "Epoch: 3600 | Train loss: 0.4744337797164917 | Test loss: 0.4903571903705597\n",
      "Epoch: 3700 | Train loss: 0.4744337797164917 | Test loss: 0.4903571605682373\n",
      "Epoch: 3800 | Train loss: 0.4744337797164917 | Test loss: 0.49035710096359253\n",
      "Epoch: 3900 | Train loss: 0.4744337499141693 | Test loss: 0.49035701155662537\n",
      "Epoch: 4000 | Train loss: 0.4744337499141693 | Test loss: 0.49035701155662537\n",
      "Epoch: 4100 | Train loss: 0.4744337499141693 | Test loss: 0.4903568923473358\n",
      "Epoch: 4200 | Train loss: 0.4744337797164917 | Test loss: 0.49035683274269104\n",
      "Epoch: 4300 | Train loss: 0.4744337797164917 | Test loss: 0.49035680294036865\n",
      "Epoch: 4400 | Train loss: 0.4744337797164917 | Test loss: 0.4903567433357239\n",
      "Epoch: 4500 | Train loss: 0.4744337797164917 | Test loss: 0.4903566837310791\n",
      "Epoch: 4600 | Train loss: 0.4744337797164917 | Test loss: 0.4903566241264343\n",
      "Epoch: 4700 | Train loss: 0.4744337797164917 | Test loss: 0.49035653471946716\n",
      "Epoch: 4800 | Train loss: 0.4744337797164917 | Test loss: 0.4903564751148224\n",
      "Epoch: 4900 | Train loss: 0.4744337499141693 | Test loss: 0.4903564751148224\n",
      "Epoch: 5000 | Train loss: 0.4744337499141693 | Test loss: 0.4903564751148224\n",
      "Epoch: 5100 | Train loss: 0.4744337797164917 | Test loss: 0.49035653471946716\n",
      "Epoch: 5200 | Train loss: 0.4744337499141693 | Test loss: 0.49035653471946716\n",
      "Epoch: 5300 | Train loss: 0.4744337797164917 | Test loss: 0.49035653471946716\n",
      "Epoch: 5400 | Train loss: 0.4744337499141693 | Test loss: 0.49035659432411194\n",
      "Epoch: 5500 | Train loss: 0.4744337797164917 | Test loss: 0.49035659432411194\n",
      "Epoch: 5600 | Train loss: 0.4744337499141693 | Test loss: 0.49035653471946716\n",
      "Epoch: 5700 | Train loss: 0.4744337797164917 | Test loss: 0.49035659432411194\n",
      "Epoch: 5800 | Train loss: 0.4744337499141693 | Test loss: 0.49035659432411194\n",
      "Epoch: 5900 | Train loss: 0.4744337499141693 | Test loss: 0.49035659432411194\n",
      "Epoch: 6000 | Train loss: 0.4744337499141693 | Test loss: 0.49035659432411194\n",
      "Epoch: 6100 | Train loss: 0.4744337499141693 | Test loss: 0.49035659432411194\n",
      "Epoch: 6200 | Train loss: 0.4744337499141693 | Test loss: 0.49035659432411194\n",
      "Epoch: 6300 | Train loss: 0.4744337499141693 | Test loss: 0.4903566241264343\n",
      "Epoch: 6400 | Train loss: 0.4744337499141693 | Test loss: 0.4903566241264343\n",
      "Epoch: 6500 | Train loss: 0.4744337499141693 | Test loss: 0.4903566241264343\n",
      "Epoch: 6600 | Train loss: 0.4744337499141693 | Test loss: 0.4903566241264343\n",
      "Epoch: 6700 | Train loss: 0.4744337499141693 | Test loss: 0.49035659432411194\n",
      "Epoch: 6800 | Train loss: 0.4744337499141693 | Test loss: 0.4903566241264343\n",
      "Epoch: 6900 | Train loss: 0.4744337499141693 | Test loss: 0.4903566241264343\n",
      "Epoch: 7000 | Train loss: 0.4744337797164917 | Test loss: 0.4903566241264343\n",
      "Epoch: 7100 | Train loss: 0.4744337499141693 | Test loss: 0.4903566241264343\n",
      "Epoch: 7200 | Train loss: 0.4744337499141693 | Test loss: 0.4903566241264343\n",
      "Epoch: 7300 | Train loss: 0.4744337797164917 | Test loss: 0.4903566241264343\n",
      "Epoch: 7400 | Train loss: 0.4744337797164917 | Test loss: 0.4903566241264343\n",
      "Epoch: 7500 | Train loss: 0.4744337797164917 | Test loss: 0.4903566837310791\n",
      "Epoch: 7600 | Train loss: 0.4744337499141693 | Test loss: 0.4903567433357239\n",
      "Epoch: 7700 | Train loss: 0.4744337499141693 | Test loss: 0.4903566837310791\n",
      "Epoch: 7800 | Train loss: 0.4744337797164917 | Test loss: 0.4903567433357239\n",
      "Epoch: 7900 | Train loss: 0.4744337499141693 | Test loss: 0.4903567433357239\n",
      "Epoch: 8000 | Train loss: 0.4744337797164917 | Test loss: 0.4903567433357239\n",
      "Epoch: 8100 | Train loss: 0.4744337797164917 | Test loss: 0.4903567433357239\n",
      "Epoch: 8200 | Train loss: 0.4744337797164917 | Test loss: 0.4903567433357239\n",
      "Epoch: 8300 | Train loss: 0.4744337797164917 | Test loss: 0.4903567433357239\n",
      "Epoch: 8400 | Train loss: 0.4744337797164917 | Test loss: 0.4903567433357239\n",
      "Epoch: 8500 | Train loss: 0.4744337797164917 | Test loss: 0.4903567433357239\n",
      "Epoch: 8600 | Train loss: 0.4744337797164917 | Test loss: 0.4903567433357239\n",
      "Epoch: 8700 | Train loss: 0.4744337499141693 | Test loss: 0.4903567433357239\n",
      "Epoch: 8800 | Train loss: 0.4744337797164917 | Test loss: 0.4903567433357239\n",
      "Epoch: 8900 | Train loss: 0.4744337797164917 | Test loss: 0.4903567433357239\n",
      "Epoch: 9000 | Train loss: 0.4744337797164917 | Test loss: 0.4903567433357239\n",
      "Epoch: 9100 | Train loss: 0.4744337499141693 | Test loss: 0.4903567433357239\n",
      "Epoch: 9200 | Train loss: 0.4744337797164917 | Test loss: 0.49035680294036865\n",
      "Epoch: 9300 | Train loss: 0.4744337797164917 | Test loss: 0.49035680294036865\n",
      "Epoch: 9400 | Train loss: 0.4744337797164917 | Test loss: 0.49035680294036865\n",
      "Epoch: 9500 | Train loss: 0.4744337797164917 | Test loss: 0.49035683274269104\n",
      "Epoch: 9600 | Train loss: 0.4744337499141693 | Test loss: 0.49035683274269104\n",
      "Epoch: 9700 | Train loss: 0.4744337499141693 | Test loss: 0.49035683274269104\n",
      "Epoch: 9800 | Train loss: 0.4744337499141693 | Test loss: 0.49035683274269104\n",
      "Epoch: 9900 | Train loss: 0.4744337797164917 | Test loss: 0.49035683274269104\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model0.train()\n",
    "    \n",
    "    y_pred = model0(X_train)\n",
    "    \n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    model0.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        test_pred = model0(X_test)\n",
    "        \n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch} | Train loss: {loss} | Test loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e68b65c-d70d-4bb1-9102-c906da954c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6317],\n",
       "        [0.6357],\n",
       "        [0.5670],\n",
       "        ...,\n",
       "        [0.0878],\n",
       "        [0.4814],\n",
       "        [0.6805]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    y_preds = model0(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dec7021a-5cad-4f37-a910-407258279a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.clone(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9432229c-b873-4138-b640-0c1492191d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predictions)):\n",
    "    if predictions[i] > .5:\n",
    "        predictions[i] = 1\n",
    "    else: \n",
    "        predictions[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f8e28d34-7d70-4852-8745-9031ddbfab3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5210592818784879"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] == y_test[i]:\n",
    "        counter += 1\n",
    "        \n",
    "counter / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d23a0b7-f06b-4080-8410-91117420bd41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
